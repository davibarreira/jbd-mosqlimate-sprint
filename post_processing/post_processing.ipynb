{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8971f979-8b92-401c-bd90-224d97fc668b",
   "metadata": {},
   "source": [
    "## Post-Processing\n",
    "\n",
    "After training and forecasting, we need to do a post-processing in order to guarantee that our output forecast makes sense.\n",
    "For example, our forecast must never go below zero, as our target is number of dengue cases, which is either zero or larger.\n",
    "Another point is that our quantiles must be monotonic, i.e. if qunatile `0.5` forecasts a value of `20`, then quantile `0.6` must forecast\n",
    "a value larger than `20`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0f5514-285d-460b-8c49-3dc1e600ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170560a-a66b-49e4-9fbf-f12d7a3b90dd",
   "metadata": {},
   "source": [
    "### Getting the intervals required by the sprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7484e87-2a6c-4ea1-b084-76879dca6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = [0.5,0.8,0.9,0.95]\n",
    "\n",
    "quantiles = [[np.round(0.5 - i/2,decimals=3), np.round(0.5 + i/2,decimals=3)]for i in intervals]\n",
    "qs = [str(i) for i in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]]\n",
    "\n",
    "def estimate_quantile(predictions,target_quantile):\n",
    "    \"\"\"\n",
    "    Estimate the value of a given quantile based on the predictions.\n",
    "\n",
    "    Parameters:\n",
    "    predictions (DataFrame): A DataFrame containing quantile predictions.\n",
    "                                     Columns should represent quantile levels (e.g., '0.1', '0.2', ..., '0.9').\n",
    "    target_quantile (float): The quantile level to estimate (e.g., 0.25, 0.75).\n",
    "\n",
    "    Returns:\n",
    "    float: The estimated value for the target quantile, interpolated if necessary.\n",
    "\n",
    "    \"\"\"\n",
    "    quantile_values = np.arange(0.1,1.0, 0.1)\n",
    "    if target_quantile in quantile_values:\n",
    "        return predictions[str(target_quantile)]\n",
    "    if target_quantile < 0.1:\n",
    "        return predictions['0.1'] - (0.1 - target_quantile)*(predictions['0.2'] - predictions['0.1'])/0.1\n",
    "    if target_quantile > 0.9:\n",
    "        return predictions['0.9'] + (target_quantile - 0.9)*(predictions['0.9'] - predictions['0.8'])/0.1\n",
    "\n",
    "    lower_bound = np.round(max(q for q in quantile_values if q < target_quantile),decimals=2)\n",
    "    upper_bound = np.round(min(q for q in quantile_values if q > target_quantile),decimals=2)\n",
    "    lower_values = predictions[str(lower_bound)]\n",
    "    upper_values = predictions[str(upper_bound)]\n",
    "    slope = (upper_values - lower_values) / (upper_bound - lower_bound)\n",
    "    return lower_values + slope * (target_quantile - lower_bound)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e175edf-5c18-4c95-8145-00c7e7ce70e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort quantiles\n",
    "def sort_quantiles(row: dict, prepend='s') -> dict:\n",
    "    quantile_cols =  [\"0.1\",\"0.2\",\"0.3\",\"0.4\",\"0.5\",\"0.6\",\"0.7\",\"0.8\",\"0.9\"]\n",
    "    # extract quantile values\n",
    "    sorted_vals = sorted(row[q] for q in quantile_cols)\n",
    "    # return a dict mapping back to the same columns\n",
    "    return {prepend+col: val for col, val in zip(quantile_cols, sorted_vals)}\n",
    "\n",
    "\n",
    "def apply_sort_quantiles(predictions, qs=['0.1','0.2','0.3','0.4','0.5','0.6','0.7','0.8','0.9']):\n",
    "    pred = predictions.with_columns(\n",
    "        pl.struct(qs).map_elements(sort_quantiles).alias(\"sorted_struct\")\n",
    "    ).unnest(\"sorted_struct\")\n",
    "\n",
    "    sqs = ['s'+q for q in qs]\n",
    "    pred = pred.with_columns(\n",
    "        pl.struct(pred.columns)\n",
    "            .map_elements(lambda row: check_monotonicity(row,sqs),return_dtype=bool).alias('mono')\n",
    "    )\n",
    "    return pred\n",
    "\n",
    "\n",
    "# Check if the sum of the orignal quantiles matches with the sorted\n",
    "def check_sum_quantiles(validation, qs=['0.1','0.2','0.3','0.4','0.5','0.6','0.7','0.8','0.9']):\n",
    "    print(len(validation.with_columns(\n",
    "        pl.sum_horizontal([pl.col(q) for q in qs]).alias('row_sum'),\n",
    "        pl.sum_horizontal([pl.col('s'+q) for q in qs]).alias('row_sum2'),\n",
    "    ).filter(\n",
    "        np.abs(pl.col('row_sum') - pl.col('row_sum2')) > 0.1\n",
    "    )) == 0)\n",
    "\n",
    "\n",
    "    # Check if all are monotonic\n",
    "    return validation.filter(~pl.col('mono'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d8bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_validation(validation):\n",
    "    validation = apply_sort_quantiles(validation)\n",
    "    validation = validation.drop(qs).rename({f's{q}': q for q in qs})\n",
    "\n",
    "    # compute quantiles for the desired quantiles\n",
    "    for q in np.hstack(quantiles):\n",
    "        validation = validation.with_columns(\n",
    "            pl.struct(validation.columns).map_elements(lambda row: estimate_quantile(row, target_quantile=q),return_dtype=float).alias(str(q))\n",
    "        )\n",
    "\n",
    "    # set negative values to 0\n",
    "    qcols = validation.columns[4:]\n",
    "    validation=validation.with_columns([\n",
    "        pl.when(pl.col(q) < 0).then(0).otherwise(pl.col(q)).alias(q)\n",
    "        for q in qcols\n",
    "    ])\n",
    "\n",
    "\n",
    "    # rename columns to match the submission format\n",
    "    # lower_95\tlower_90\tlower_80\tlower_50\tpred\tupper_50\tupper_80\tupper_90\tupper_95\tdate\n",
    "    # [2.5, 5, 10, 25, 50, 75, 90, 95, 97.5]\n",
    "    columns_submission = ['lower_95','lower_90','lower_80','lower_50','pred','upper_50','upper_80','upper_90','upper_95','date']\n",
    "    validation = validation.rename(\n",
    "        {\n",
    "            '0.025':'lower_95',\n",
    "            '0.05' :'lower_90',\n",
    "            '0.1'  :'lower_80',\n",
    "            '0.25' :'lower_50',\n",
    "            '0.5':'pred',\n",
    "            '0.75' :'upper_50',\n",
    "            '0.9'  :'upper_80',\n",
    "            '0.95' :'upper_90',\n",
    "            '0.975':'upper_95',\n",
    "        })[columns_submission]\n",
    "    return validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3bcca7f-c168-40e6-972a-8ee9f2d5d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import predictions\n",
    "validation1 = pl.read_parquet('../data/4_model_output/validation_sprint_1.parquet').with_columns(\n",
    "    pl.col(\"date\").cast(pl.Date)\n",
    ")\n",
    "validation2 = pl.read_parquet('../data/4_model_output/validation_sprint_2.parquet').with_columns(\n",
    "    pl.col(\"date\").cast(pl.Date)\n",
    ")\n",
    "validation3 = pl.read_parquet('../data/4_model_output/validation_sprint_3.parquet').with_columns(\n",
    "    pl.col(\"date\").cast(pl.Date)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b48566c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/kh2xcmy51n70hznv18vzsqxr0000gn/T/ipykernel_91695/3687623414.py:22: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  pred = predictions.with_columns(\n",
      "/var/folders/sz/kh2xcmy51n70hznv18vzsqxr0000gn/T/ipykernel_91695/3687623414.py:22: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  pred = predictions.with_columns(\n",
      "/var/folders/sz/kh2xcmy51n70hznv18vzsqxr0000gn/T/ipykernel_91695/3687623414.py:22: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  pred = predictions.with_columns(\n"
     ]
    }
   ],
   "source": [
    "submission1 = post_process_validation(validation1)\n",
    "submission2 = post_process_validation(validation2)\n",
    "submission3 = post_process_validation(validation3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44a53aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "[True, True, True, True, True, True, True, True, True]\n",
      "[True, True, True, True, True, True, True, True, True]\n",
      "[True, True, True, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "def check_monotonicity(row, qs):\n",
    "    vals = [row[q] for q in qs]\n",
    "    return np.all(np.diff(vals) >= 0)\n",
    "\n",
    "def apply_check_monotonicity(predictions, qs=['0.1','0.2','0.3','0.4','0.5','0.6','0.7','0.8','0.9']):\n",
    "    predictions = predictions.with_columns(\n",
    "        pl.struct(predictions.columns)\n",
    "            .map_elements(lambda row: check_monotonicity(row,qs),return_dtype=bool).alias('mono')\n",
    "    )\n",
    "    return predictions.filter(~pl.col('mono')).shape[0] == 0\n",
    "\n",
    "\n",
    "def apply_check_nonnegative(submission, qs=['lower_95','lower_90','lower_80','lower_50','pred','upper_50','upper_80','upper_90','upper_95']):\n",
    "    return [submission.filter(pl.col(q) < 0).shape[0] == 0 for q in qs]\n",
    "\n",
    "print(apply_check_monotonicity(submission1, qs=['lower_95','lower_90','lower_80','lower_50','pred','upper_50','upper_80','upper_90','upper_95']))\n",
    "print(apply_check_monotonicity(submission2, qs=['lower_95','lower_90','lower_80','lower_50','pred','upper_50','upper_80','upper_90','upper_95']))\n",
    "print(apply_check_monotonicity(submission3, qs=['lower_95','lower_90','lower_80','lower_50','pred','upper_50','upper_80','upper_90','upper_95']))\n",
    "\n",
    "\n",
    "print(apply_check_nonnegative(submission1, qs=['lower_95','lower_90','lower_80','lower_50','pred','upper_50','upper_80','upper_90','upper_95']))\n",
    "print(apply_check_nonnegative(submission2, qs=['lower_95','lower_90','lower_80','lower_50','pred','upper_50','upper_80','upper_90','upper_95']))\n",
    "print(apply_check_nonnegative(submission3, qs=['lower_95','lower_90','lower_80','lower_50','pred','upper_50','upper_80','upper_90','upper_95']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d2b543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprint2025",
   "language": "python",
   "name": "sprint2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
